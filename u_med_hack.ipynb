{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "u-med hack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Loleiying/HIPPOCAMPAL-OSCILLATORY-PATTERNS-DURING-ASSOCIATE-RECOGNITION-MEMORY/blob/master/u_med_hack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1kceNfoYEFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MxgBC51YFKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read data\n",
        "egg_en = pd.read_csv(\"encoding_filtered2to100Hz_cep.csv\")\n",
        "egg_re = pd.read_csv(\"retrieval_filtered2to100Hz_cep.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDSBGK5DawPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# take only the first 300 attributes for model training\n",
        "X_encoding = egg_en.iloc[:,1:301]\n",
        "y_encoding_target = egg_en.iloc[:,-1]\n",
        "X_retri = egg_re.iloc[:,1:301]\n",
        "y_retri_target = egg_re.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4QAhYB4FCeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get classification report\n",
        "def get_report(y_true, y_pred):\n",
        "  target_names = ['Intact-Rearranged', 'Intact-Intact']\n",
        "  return classification_report(y_true, y_pred, target_names=target_names)\n",
        "\n",
        "# train and test the model\n",
        "def test(model, df, X, Y):\n",
        "  score = []\n",
        "  # KFold\n",
        "  kf = KFold(n_splits=5)\n",
        "  for train_index, test_index in kf.split(df.index):\n",
        "    X_train, X_test, y_train, y_test = X.values[train_index], X.values[test_index], Y.values[train_index], Y.values[test_index]\n",
        "    model.fit(X_train, y_train) # train the model \n",
        "    score.append(model.score(X_test, y_test)) # score of testing\n",
        "    ypred = model.predict(X_test) # prediction\n",
        "    ag = ~(ypred==y_test)\n",
        "    wrong_ag.extend(test_index[ag])\n",
        "    print(get_report(y_test, ypred)) # get classification report\n",
        "  print(\"Mean score\", np.array(score).mean()) # mean score of the model\n",
        "  return wrong_ag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBTwyE1uELNW",
        "colab_type": "code",
        "outputId": "d5f88ae9-57a5-407f-9a35-53502c329474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Downsampling\n",
        "from sklearn.utils import resample\n",
        "intact_intact_encoding = egg_en[egg_en['cat']==1] # majority\n",
        "intact_rearranged_encoding = egg_en[egg_en['cat']==0] # minority \n",
        "df_majority = intact_intact_encoding\n",
        "df_minority = intact_rearranged_encoding\n",
        "\n",
        "df_majority_downsample = resample(df_majority, \n",
        "                                 replace=True,     \n",
        "                                 n_samples=2500,    \n",
        "                                 random_state=123) \n",
        "df_train_en = pd.concat([df_majority_downsample, df_minority])\n",
        "# Display new class counts\n",
        "# print (df_train_re.cat.value_counts())\n",
        "\n",
        "intact_intact_re = egg_re[egg_re['cat']==1]\n",
        "intact_rearranged_re = egg_re[egg_re['cat']==0]\n",
        "df_majority = intact_intact_re\n",
        "df_minority = intact_rearranged_re\n",
        "\n",
        "df_majority_downsample = resample(df_majority, \n",
        "                                 replace=True,     \n",
        "                                 n_samples=2500,    \n",
        "                                 random_state=123) \n",
        "df_train_re = pd.concat([df_majority_downsample, df_minority])\n",
        "\n",
        "# Display new class counts\n",
        "# print(df_train.cat.value_counts())\n",
        "\n",
        "X_en = df_train_en.iloc[:,1:301]\n",
        "y_en = df_train_en.iloc[:,-1]\n",
        "X_re = df_train_re.iloc[:,1:301]\n",
        "y_re = df_train_re.iloc[:,-1]\n",
        "\n",
        "# downsampling testing\n",
        "rf = RandomForestClassifier(n_estimators=50)\n",
        "wrong_ag_en = test(rf, df_train_en, X_en, y_en)\n",
        "len(wrong_ag_en)\n",
        "#np.savetxt(\"wrong_encoding.csv\", wrong_ag_en, delimiter=\",\", fmt='%d')\n",
        "wrong_ag_re = test(rf, df_train_re, X_re, y_re)\n",
        "len(wrong_ag_re)\n",
        "#np.savetxt(\"wrong_retrieval.csv\", wrong_ag_re, delimiter=\",\", fmt='%d')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Intact-Rearranged       0.00      0.00      0.00         0\n",
            "    Intact-Intact       1.00      0.21      0.34      1002\n",
            "\n",
            "         accuracy                           0.21      1002\n",
            "        macro avg       0.50      0.10      0.17      1002\n",
            "     weighted avg       1.00      0.21      0.34      1002\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Intact-Rearranged       0.00      0.00      0.00         0\n",
            "    Intact-Intact       1.00      0.18      0.31      1002\n",
            "\n",
            "         accuracy                           0.18      1002\n",
            "        macro avg       0.50      0.09      0.15      1002\n",
            "     weighted avg       1.00      0.18      0.31      1002\n",
            "\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Intact-Rearranged       0.56      0.62      0.59       505\n",
            "    Intact-Intact       0.57      0.51      0.54       496\n",
            "\n",
            "         accuracy                           0.56      1001\n",
            "        macro avg       0.56      0.56      0.56      1001\n",
            "     weighted avg       0.56      0.56      0.56      1001\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Intact-Rearranged       1.00      0.13      0.24      1001\n",
            "    Intact-Intact       0.00      0.00      0.00         0\n",
            "\n",
            "         accuracy                           0.13      1001\n",
            "        macro avg       0.50      0.07      0.12      1001\n",
            "     weighted avg       1.00      0.13      0.24      1001\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Intact-Rearranged       1.00      0.15      0.26      1001\n",
            "    Intact-Intact       0.00      0.00      0.00         0\n",
            "\n",
            "         accuracy                           0.15      1001\n",
            "        macro avg       0.50      0.07      0.13      1001\n",
            "     weighted avg       1.00      0.15      0.26      1001\n",
            "\n",
            "Mean score 0.24707508060801472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Intact-Rearranged       0.00      0.00      0.00         0\n",
            "    Intact-Intact       1.00      0.28      0.44       943\n",
            "\n",
            "         accuracy                           0.28       943\n",
            "        macro avg       0.50      0.14      0.22       943\n",
            "     weighted avg       1.00      0.28      0.44       943\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Intact-Rearranged       0.00      0.00      0.00         0\n",
            "    Intact-Intact       1.00      0.30      0.46       943\n",
            "\n",
            "         accuracy                           0.30       943\n",
            "        macro avg       0.50      0.15      0.23       943\n",
            "     weighted avg       1.00      0.30      0.46       943\n",
            "\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Intact-Rearranged       0.42      0.64      0.51       329\n",
            "    Intact-Intact       0.73      0.52      0.61       614\n",
            "\n",
            "         accuracy                           0.57       943\n",
            "        macro avg       0.58      0.58      0.56       943\n",
            "     weighted avg       0.62      0.57      0.57       943\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Intact-Rearranged       1.00      0.07      0.13       943\n",
            "    Intact-Intact       0.00      0.00      0.00         0\n",
            "\n",
            "         accuracy                           0.07       943\n",
            "        macro avg       0.50      0.03      0.06       943\n",
            "     weighted avg       1.00      0.07      0.13       943\n",
            "\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Intact-Rearranged       1.00      0.06      0.12       942\n",
            "    Intact-Intact       0.00      0.00      0.00         0\n",
            "\n",
            "         accuracy                           0.06       942\n",
            "        macro avg       0.50      0.03      0.06       942\n",
            "     weighted avg       1.00      0.06      0.12       942\n",
            "\n",
            "Mean score 0.2551564438380468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEub8Uawsa2-",
        "colab_type": "code",
        "outputId": "9eb9ce22-b983-418b-a7d8-0c852eb25b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "#SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "sm = SMOTE(random_state=12)\n",
        "x_train_en, y_train_en = sm.fit_sample(X_encoding, y_encoding_target)\n",
        "x_train_en = pd.DataFrame(x_train_en)\n",
        "y_train_en = pd.DataFrame(y_train_en)\n",
        "df_train_en = (pd.concat([x_train_en, y_train_en])).reset_index()\n",
        "#print (y_encoding_target.value_counts() , np.bincount(y_train_en))\n",
        "\n",
        "x_train_re, y_train_re = sm.fit_sample(X_retri, y_retri_target)\n",
        "x_train_re = pd.DataFrame(x_train_re)\n",
        "y_train_re = pd.DataFrame(y_train_re)\n",
        "df_train_re = (pd.concat([x_train_re, y_train_re])).reset_index()\n",
        "\n",
        "# downsampling testing\n",
        "rf = RandomForestClassifier(n_estimators=50)\n",
        "wrong_ag_en1 = test(rf, df_train_en, x_train_en, y_train_en)\n",
        "len(wrong_ag_en1)\n",
        "#np.savetxt(\"wrong_encoding.csv\", wrong_ag_en, delimiter=\",\", fmt='%d')\n",
        "wrong_ag_re1 = test(rf, df_train_re, x_train_re, y_train_re)\n",
        "#len(wrong_ag_re1)\n",
        "#np.savetxt(\"wrong_retrieval.csv\", wrong_ag_re, delimiter=\",\", fmt='%d')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-b47b47461f21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# downsampling testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mwrong_ag_en1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrong_ag_en1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#np.savetxt(\"wrong_encoding.csv\", wrong_ag_en, delimiter=\",\", fmt='%d')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-107-0528b5951d28>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, df, X, Y)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# score of testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 17424 is out of bounds for axis 0 with size 17424"
          ]
        }
      ]
    }
  ]
}